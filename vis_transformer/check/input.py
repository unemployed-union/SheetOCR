import torch
import pandas as pd
import numpy as np
from torch.utils.data import DataLoader
from ..dataset import SheetMusicDataset, collate_fn
from ..tokenizer import Tokenizer
import sys

def check_data_text_only():
    print("ğŸ•µï¸â€â™‚ï¸ WSLìš© ë°ì´í„° ì •ë°€ ì§„ë‹¨ ì‹œì‘...\n")

    # 1. Vocab ì ê²€ (ìŠ¤í˜ì´ìŠ¤ë°” ìƒì¡´ í™•ì¸)
    print("[1] Vocab íŒŒì¼ ì ê²€")
    try:
        with open("vocab.txt", "r", encoding="utf-8") as f:
            # [í•µì‹¬] strip() ëŒ€ì‹  replaceë¡œ ì½ê¸°
            vocab_list = [line.replace('\n', '').replace('\r', '') for line in f.readlines()]
        
        if ' ' in vocab_list:
            print(f"   âœ… í•©ê²©! ìŠ¤í˜ì´ìŠ¤ë°”ê°€ {vocab_list.index(' ')}ë²ˆ ì¸ë±ìŠ¤ì— ì¡´ì¬í•©ë‹ˆë‹¤.")
        else:
            print("   ğŸš¨ ë¶ˆí•©ê²©! ìŠ¤í˜ì´ìŠ¤ë°”ê°€ ì—†ìŠµë‹ˆë‹¤. main.pyì˜ vocab ì½ëŠ” ë¶€ë¶„ì„ ê³ ì¹˜ì„¸ìš”!")
    except Exception as e:
        print(f"   âŒ ì—ëŸ¬: {e}")
        return

    # 2. í† í¬ë‚˜ì´ì € ì ê²€
    tokenizer = Tokenizer(vocab_list)
    print(f"\n[2] í† í¬ë‚˜ì´ì € í…ŒìŠ¤íŠ¸")
    test_str = "434 ê³¡" # ìˆ«ìì™€ ê³µë°± í¬í•¨
    encoded = tokenizer.encode(test_str)
    decoded = tokenizer.decode(encoded)
    print(f"   ì…ë ¥: '{test_str}'")
    print(f"   ë³€í™˜(ID): {encoded}")
    print(f"   ë³µì›: '{decoded}'")
    
    if len(encoded) < 4: # 4,3,4, ,ê³¡ (5ê°œ)ì—¬ì•¼ í•˜ëŠ”ë° ì¤„ì—ˆë‹¤ë©´
        print("   ğŸš¨ ê²½ê³ : ê¸€ì ìˆ˜ê°€ ì¤„ì–´ë“¤ì—ˆìŠµë‹ˆë‹¤! (ì‚­ì œë¨)")
    else:
        print("   âœ… ì •ìƒ: ëª¨ë“  ê¸€ìê°€ ì˜ ì‚´ì•„ìˆìŠµë‹ˆë‹¤.")

    # 3. ì´ë¯¸ì§€ ë°ì´í„°(í”½ì…€) ì ê²€
    print(f"\n[3] ì´ë¯¸ì§€ í…ì„œ ê°’ ì ê²€ (ëˆˆ ëŒ€ì‹  ìˆ«ìë¡œ í™•ì¸)")
    try:
        df = pd.read_json("dataset_vit/train_final/metadata.jsonl", lines=True).iloc[:4]
        # Transform ì—†ì´ Raw ë°ì´í„° í™•ì¸ (dataset ë‚´ë¶€ ë¡œì§ë§Œ í†µê³¼)
        dataset = SheetMusicDataset("dataset_vit/train_final", df, tokenizer, transform=None)
        loader = DataLoader(dataset, batch_size=4, collate_fn=collate_fn)
        
        images, targets, lengths = next(iter(loader))
        
        # í†µê³„ ê³„ì‚°
        min_val = images.min().item()
        max_val = images.max().item()
        mean_val = images.mean().item()
        
        print(f"   ğŸ“Š í”½ì…€ ë²”ìœ„: {min_val:.4f} ~ {max_val:.4f}")
        print(f"   ğŸ“Š í”½ì…€ í‰ê· : {mean_val:.4f}")

        # íŒë‹¨ ë¡œì§
        if min_val == max_val:
            print("   ğŸš¨ [ì¹˜ëª…ì ] ì´ë¯¸ì§€ê°€ ë‹¨ìƒ‰(ì „ë¶€ ê²€ì • or í°ìƒ‰)ì…ë‹ˆë‹¤! ì „ì²˜ë¦¬ ì½”ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        elif min_val < 0 and max_val > 0:
            print("   âœ… ì •ìƒ: ì´ë¯¸ì§€ê°€ -1 ~ 1 ì‚¬ì´ë¡œ ì˜ ì •ê·œí™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        elif min_val >= 0 and max_val <= 1.0:
             print("   âœ… ì •ìƒ: ì´ë¯¸ì§€ê°€ 0 ~ 1 ì‚¬ì´ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("   âš ï¸ ì£¼ì˜: í”½ì…€ ë²”ìœ„ê°€ íŠ¹ì´í•©ë‹ˆë‹¤. (í•˜ì§€ë§Œ ë‹¨ìƒ‰ì€ ì•„ë‹˜)")

    except Exception as e:
        print(f"   âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì—ëŸ¬: {e}")

if __name__ == "__main__":
    check_data_text_only()